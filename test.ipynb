{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import clip\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torchvision import transforms as T\n",
    "\n",
    "from models.lm4cv import mean_mahalanobis_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder, preprocess = clip.load('ViT-B/32', device='cpu')\n",
    "raw_concepts = open(\"data/LM4CV/cub_attributes.txt\", 'r').read().strip().split(\"\\n\")\n",
    "\n",
    "full_concept_emb = []   # Matrix T\n",
    "batch_size = 32\n",
    "\n",
    "prompt_prefix = 'The bird has '\n",
    "num_batches = len(raw_concepts) // batch_size + 1\n",
    "for i in range(num_batches):\n",
    "    batch_concepts = raw_concepts[i * batch_size: (i + 1) * batch_size]\n",
    "    batch_concept_emb = clip.tokenize([prompt_prefix + attr for attr in batch_concepts])\n",
    "    full_concept_emb.append(embedder.encode_text(batch_concept_emb).detach().cpu())\n",
    "\n",
    "full_concept_emb = torch.concat(full_concept_emb).float()\n",
    "full_concept_emb = full_concept_emb / full_concept_emb.norm(dim=-1, keepdim=True)   # Matrix T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 512\n",
    "K = 100\n",
    "N = 1000\n",
    "T = torch.randn(N, D)\n",
    "E = torch.randn(K, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "510.35193"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implementation 1\n",
    "def mahalanobis_distance(x, mu, sigma_inv):\n",
    "    x = x - mu.unsqueeze(0)\n",
    "    return torch.diag(x @ sigma_inv @ x.T).mean()\n",
    "\n",
    "mu = torch.mean(full_concept_emb, dim=0)\n",
    "sigma_inv = torch.tensor(np.linalg.inv(torch.cov(full_concept_emb.T)))\n",
    "mean_distance = np.mean([mahalanobis_distance(embed, mu, sigma_inv) for embed in full_concept_emb])\n",
    "mean_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0358)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_norm = torch.linalg.norm(E, dim=-1, keepdim=True)\n",
    "mahalanobis_loss = (mahalanobis_distance(E / e_norm, mu, sigma_inv) - mean_distance) / (mean_distance ** 3)\n",
    "mahalanobis_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implementation 2\n",
    "def mahalanobis_distance2(x, mu, sigma_inv):\n",
    "    x = x - mu\n",
    "    return torch.sqrt(x @ sigma_inv @ x.T)\n",
    "\n",
    "torch.tensor([mahalanobis_distance2(e_row, mu, sigma_inv) for e_row in E]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_psd(mat):\n",
    "    return bool((mat == mat.T).all() and (torch.linalg.eigvals(mat).real>=0).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_psd(torch.cov(full_concept_emb.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mahalanobis(u, v, cov):\n",
    "    delta = u - v\n",
    "    m = torch.dot(delta, torch.matmul(torch.inverse(cov), delta))\n",
    "    return m\n",
    "    # return torch.sqrt(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(6.4656e+09),\n",
       " tensor(-4.8790e+09),\n",
       " tensor(8.4279e+09),\n",
       " tensor(-6.2947e+09),\n",
       " tensor(-2.2306e+10),\n",
       " tensor(2.2523e+10),\n",
       " tensor(2.6177e+09),\n",
       " tensor(3.9648e+10),\n",
       " tensor(-2.6618e+09),\n",
       " tensor(2.6030e+09),\n",
       " tensor(-7.3518e+09),\n",
       " tensor(3.6626e+08),\n",
       " tensor(5.9266e+08),\n",
       " tensor(2.4756e+10),\n",
       " tensor(6.8798e+09),\n",
       " tensor(5.3886e+09),\n",
       " tensor(6.8810e+08),\n",
       " tensor(1.7023e+10),\n",
       " tensor(1.0625e+10),\n",
       " tensor(-1.9214e+10),\n",
       " tensor(2.1618e+10),\n",
       " tensor(-2.0238e+09),\n",
       " tensor(1.2442e+10),\n",
       " tensor(8.0594e+08),\n",
       " tensor(-4.4186e+09),\n",
       " tensor(5.0296e+09),\n",
       " tensor(1.7522e+10),\n",
       " tensor(-1.6372e+09),\n",
       " tensor(2.4280e+09),\n",
       " tensor(9.8822e+09),\n",
       " tensor(-3.6955e+10),\n",
       " tensor(5.1362e+09),\n",
       " tensor(7.4042e+08),\n",
       " tensor(-3.5569e+09),\n",
       " tensor(-5.0281e+09),\n",
       " tensor(3.9498e+09),\n",
       " tensor(-8.1825e+09),\n",
       " tensor(-2.8514e+10),\n",
       " tensor(3.7873e+09),\n",
       " tensor(8.2648e+09),\n",
       " tensor(1.2701e+10),\n",
       " tensor(-8.7634e+09),\n",
       " tensor(-9.5503e+09),\n",
       " tensor(-5.9256e+09),\n",
       " tensor(7.4480e+09),\n",
       " tensor(1.6485e+10),\n",
       " tensor(5.1022e+10),\n",
       " tensor(-5.2020e+09),\n",
       " tensor(1.6261e+10),\n",
       " tensor(2.3772e+09),\n",
       " tensor(-7.0500e+08),\n",
       " tensor(-1.3358e+10),\n",
       " tensor(-3.2456e+09),\n",
       " tensor(1.7699e+09),\n",
       " tensor(-2.5654e+10),\n",
       " tensor(-2.2788e+10),\n",
       " tensor(1.0584e+09),\n",
       " tensor(-8.5334e+09),\n",
       " tensor(2.6114e+10),\n",
       " tensor(-33012864.),\n",
       " tensor(1.5501e+09),\n",
       " tensor(9.6406e+09),\n",
       " tensor(-1.4659e+09),\n",
       " tensor(-2.6519e+10),\n",
       " tensor(1.6363e+09),\n",
       " tensor(2.1348e+09),\n",
       " tensor(-1.2603e+10),\n",
       " tensor(2.9096e+09),\n",
       " tensor(-1.5805e+09),\n",
       " tensor(-2.2038e+09),\n",
       " tensor(3.6274e+09),\n",
       " tensor(-1.2346e+10),\n",
       " tensor(3.1395e+09),\n",
       " tensor(-4.2890e+09),\n",
       " tensor(-4.5950e+09),\n",
       " tensor(1.8688e+10),\n",
       " tensor(-4.1117e+10),\n",
       " tensor(-6.7021e+08),\n",
       " tensor(-1.3972e+10),\n",
       " tensor(5.9522e+09),\n",
       " tensor(-4.2674e+10),\n",
       " tensor(2.9309e+10),\n",
       " tensor(-9.3298e+09),\n",
       " tensor(1.8803e+10),\n",
       " tensor(-5.2236e+09),\n",
       " tensor(1.0584e+10),\n",
       " tensor(3.1255e+09),\n",
       " tensor(5.6443e+09),\n",
       " tensor(-1.0679e+10),\n",
       " tensor(1.6757e+10),\n",
       " tensor(-4.5074e+10),\n",
       " tensor(1.8387e+10),\n",
       " tensor(2.6268e+10),\n",
       " tensor(2.7281e+10),\n",
       " tensor(1.3856e+10),\n",
       " tensor(-1.0909e+10),\n",
       " tensor(-3.8039e+09),\n",
       " tensor(-1.8269e+10),\n",
       " tensor(-2.6318e+10),\n",
       " tensor(1.0731e+10)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mahalanobis_distance2(x, mu, sigma_inv):\n",
    "    x = x - mu\n",
    "    return x @ sigma_inv @ x.T\n",
    "\n",
    "mu = torch.mean(full_concept_emb, dim=0)\n",
    "\n",
    "sigma = torch.cov(full_concept_emb.T)\n",
    "sigma_inv = torch.linalg.inv(torch.cov(full_concept_emb.T))\n",
    "\n",
    "distances = [mahalanobis(e_row, mu, sigma) for e_row in E]\n",
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3909e-04,  1.0566e-05, -4.4615e-06,  ..., -4.1785e-05,\n",
       "          1.5213e-05, -1.6853e-05],\n",
       "        [ 1.0566e-05,  2.7116e-04,  5.5303e-05,  ...,  5.3137e-05,\n",
       "         -9.1934e-05, -2.8730e-05],\n",
       "        [-4.4615e-06,  5.5303e-05,  1.4856e-04,  ...,  5.7498e-05,\n",
       "         -2.5527e-05, -2.8638e-05],\n",
       "        ...,\n",
       "        [-4.1785e-05,  5.3137e-05,  5.7498e-05,  ...,  5.3831e-04,\n",
       "         -1.3482e-04,  2.9747e-05],\n",
       "        [ 1.5213e-05, -9.1934e-05, -2.5527e-05,  ..., -1.3482e-04,\n",
       "          2.2928e-04, -3.7178e-06],\n",
       "        [-1.6853e-05, -2.8730e-05, -2.8638e-05,  ...,  2.9747e-05,\n",
       "         -3.7178e-06,  2.2496e-04]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cov(full_concept_emb.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5248255.0000,  5302723.0000,  -696952.1875,  ...,\n",
       "          6577713.5000,  4749001.0000, -2328161.2500],\n",
       "        [ 5299397.0000,  6869843.0000,  -698490.3750,  ...,\n",
       "         10132456.0000,  6002626.5000, -2560786.5000],\n",
       "        [ -711532.6250,  -716567.8750,  1068546.5000,  ...,\n",
       "          2252066.5000,  -300771.9688,  -500953.2812],\n",
       "        ...,\n",
       "        [ 6409478.5000,  9936476.0000,  2330944.0000,  ...,\n",
       "         45804552.0000, 11349803.0000, -6523319.5000],\n",
       "        [ 4721849.5000,  5973281.5000,  -276246.5000,  ...,\n",
       "         11499574.0000,  6372226.5000, -3210215.5000],\n",
       "        [-2303082.2500, -2531706.7500,  -514123.4688,  ...,\n",
       "         -6549449.5000, -3192587.7500,  2575318.0000]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_inv = torch.linalg.inv(torch.cov(full_concept_emb.T))\n",
    "sigma_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3909e-04,  1.0566e-05, -4.4615e-06,  ..., -4.1785e-05,\n",
       "          1.5213e-05, -1.6853e-05],\n",
       "        [ 1.0566e-05,  2.7116e-04,  5.5303e-05,  ...,  5.3137e-05,\n",
       "         -9.1934e-05, -2.8730e-05],\n",
       "        [-4.4615e-06,  5.5303e-05,  1.4856e-04,  ...,  5.7498e-05,\n",
       "         -2.5527e-05, -2.8638e-05],\n",
       "        ...,\n",
       "        [-4.1785e-05,  5.3137e-05,  5.7498e-05,  ...,  5.3831e-04,\n",
       "         -1.3482e-04,  2.9747e-05],\n",
       "        [ 1.5213e-05, -9.1934e-05, -2.5527e-05,  ..., -1.3482e-04,\n",
       "          2.2928e-04, -3.7178e-06],\n",
       "        [-1.6853e-05, -2.8730e-05, -2.8638e-05,  ...,  2.9747e-05,\n",
       "         -3.7178e-06,  2.2496e-04]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cov(full_concept_emb.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.39089103e-04,  1.05659480e-05, -4.46153526e-06, ...,\n",
       "        -4.17851290e-05,  1.52127005e-05, -1.68525966e-05],\n",
       "       [ 1.05659480e-05,  2.71160301e-04,  5.53028536e-05, ...,\n",
       "         5.31374681e-05, -9.19336796e-05, -2.87299555e-05],\n",
       "       [-4.46153526e-06,  5.53028536e-05,  1.48562504e-04, ...,\n",
       "         5.74976233e-05, -2.55273265e-05, -2.86382370e-05],\n",
       "       ...,\n",
       "       [-4.17851290e-05,  5.31374681e-05,  5.74976233e-05, ...,\n",
       "         5.38313309e-04, -1.34823570e-04,  2.97474284e-05],\n",
       "       [ 1.52127005e-05, -9.19336796e-05, -2.55273265e-05, ...,\n",
       "        -1.34823570e-04,  2.29284547e-04, -3.71777220e-06],\n",
       "       [-1.68525966e-05, -2.87299555e-05, -2.86382370e-05, ...,\n",
       "         2.97474284e-05, -3.71777220e-06,  2.24960100e-04]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cov(np.array(full_concept_emb.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "logichoi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
