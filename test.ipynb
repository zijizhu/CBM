{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import clip\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from pprint import pprint\n",
    "from torchvision import transforms as T\n",
    "from datasets.cub_dataset import CUBDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos = nn.CosineSimilarity()\n",
    "a = torch.randn(100, 10)\n",
    "b = torch.randn(10)\n",
    "res = cos(b, a)\n",
    "res.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test implementation of loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated concept embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "embedder, preprocess = clip.load('ViT-B/32', device='cpu')\n",
    "raw_concepts = open(\"data/LM4CV/cub_attributes.txt\", 'r').read().strip().split(\"\\n\")\n",
    "\n",
    "full_concept_emb = []   # Matrix T\n",
    "batch_size = 32\n",
    "\n",
    "prompt_prefix = 'The bird has '\n",
    "num_batches = len(raw_concepts) // batch_size + 1\n",
    "for i in range(num_batches):\n",
    "    batch_concepts = raw_concepts[i * batch_size: (i + 1) * batch_size]\n",
    "    batch_concept_emb = clip.tokenize([prompt_prefix + attr for attr in batch_concepts])\n",
    "    full_concept_emb.append(embedder.encode_text(batch_concept_emb).detach().cpu())\n",
    "\n",
    "full_concept_emb = torch.concat(full_concept_emb).float()\n",
    "full_concept_emb = full_concept_emb / full_concept_emb.norm(dim=-1, keepdim=True)   # Matrix T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Init some random values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 512\n",
    "K = 100\n",
    "N = 1000\n",
    "T = torch.randn(N, D)\n",
    "E = torch.randn(K, D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mean_squared_mahalanobis(x: torch.Tensor, mu: torch.Tensor, sigma_inv):\n",
    "    '''Computes the mean of squared mahalanobis distances from a vector or a set of vectors to the distribution\n",
    "    with mean my and and inverse covariant matrix sigma_inv.\n",
    "    Implementation from https://github.com/wangyu-ustc/LM4CV/blob/main/utils/train_utils.py#L263\n",
    "    \n",
    "    Args:\n",
    "        x (Tensor[M, D]) or (Tensor[D]): a vector or a set of vector of length D.\n",
    "        distribution (Tensor[N, D]) a matrix of N vectors of length D\n",
    "    \n",
    "    Returns:\n",
    "        Tensor[]: a scaler tensor, which is the mahalanobis distance from vec to the distribution.\n",
    "    '''\n",
    "    delta = x - mu.unsqueeze(0)\n",
    "    return torch.diag(delta @ sigma_inv @ delta.T).mean()\n",
    "\n",
    "\n",
    "class Stage1Criterion(nn.Module):\n",
    "    def __init__(self, regularization=True, division_power=3) -> None:\n",
    "        super().__init__()\n",
    "        self.xe = nn.CrossEntropyLoss()\n",
    "        self.regularization = regularization\n",
    "        self.division_power = division_power\n",
    "    \n",
    "    def forward(self, outputs: torch.Tensor, targets, weights, full_concept_emb):\n",
    "        # xe_loss = self.xe(outputs, targets)\n",
    "        # if not self.regularization:\n",
    "        #     return xe_loss\n",
    "\n",
    "        # Original implementation from https://github.com/wangyu-ustc/LM4CV/blob/main/utils/train_utils.py#L208\n",
    "        # which is different to the one described in the paper.\n",
    "        weights_norm = torch.linalg.norm(weights, dim=-1, keepdim=True)\n",
    "        mu = torch.mean(full_concept_emb, dim=0)\n",
    "        sigma_inv = torch.tensor(np.linalg.inv(torch.cov(full_concept_emb.T)))    # Using torch.inverse will have different result\n",
    "        # Alternate implementation: sigma_inv = torch.inverse(torch.cov(distribution.T))\n",
    "\n",
    "        mean_distance = torch.stack([_mean_squared_mahalanobis(embed, mu, sigma_inv)\n",
    "                                     for embed\n",
    "                                     in full_concept_emb]).mean().to(outputs.device)\n",
    "\n",
    "        mahalanobis_loss = _mean_squared_mahalanobis(weights / weights_norm, mu, sigma_inv)\n",
    "        mahalanobis_loss_scaled = (mahalanobis_loss - mean_distance) / (mean_distance ** self.division_power)\n",
    "\n",
    "        return torch.abs(mahalanobis_loss_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0946)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_layer = Stage1Criterion()\n",
    "loss_layer(torch.tensor([]), torch.tensor([]), E, full_concept_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation from original paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0946)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribute_embeddings = full_concept_emb\n",
    "\n",
    "def mahalanobis_distance(x, mu, sigma_inv):\n",
    "    x = x - mu.unsqueeze(0)\n",
    "    return torch.diag(x @ sigma_inv @ x.T).mean()\n",
    "\n",
    "model = [E]\n",
    "\n",
    "mu = torch.mean(attribute_embeddings, dim=0)\n",
    "sigma_inv = torch.tensor(np.linalg.inv(torch.cov(attribute_embeddings.T)))\n",
    "configs = {\n",
    "    'mu': mu,\n",
    "    'sigma_inv': sigma_inv,\n",
    "    'mean_distance': np.mean([mahalanobis_distance(embed, mu, sigma_inv) for embed in attribute_embeddings])\n",
    "}\n",
    "\n",
    "mahalanobis_loss = (mahalanobis_distance(E/E.norm(dim=-1, keepdim=True), configs['mu'],\n",
    "                    configs['sigma_inv']) - configs['mean_distance']) / (configs['mean_distance']**3)\n",
    "torch.abs(mahalanobis_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "logichoi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
